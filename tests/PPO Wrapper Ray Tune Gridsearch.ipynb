{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8df2bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\tensorflow_probability\\python\\__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if (distutils.version.LooseVersion(tf.__version__) <\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import random, math\n",
    "import numpy as np\n",
    "import arcade\n",
    "from skimage import data, color\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "from PIL import Image\n",
    "\n",
    "        \n",
    "from LightEnvCopy import LightEnv\n",
    "\n",
    "import gym.spaces\n",
    "from gym.spaces import Discrete, Box\n",
    "\n",
    "from ray.rllib.env.env_context import EnvContext\n",
    "from ray.rllib.models import ModelCatalog\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "# Do the math to figure out our screen dimensions\n",
    "SCREEN_WIDTH = 800\n",
    "SCREEN_HEIGHT = 600\n",
    "SCREEN_TITLE = \"Game 1: Let There Be Light!\"\n",
    "\n",
    "# COnvenient data structure to hold information about actions\n",
    "Action = namedtuple('Action', 'name index delta_i delta_j')\n",
    "\n",
    "up = Action('up', 0, -1, 0)    \n",
    "down = Action('down', 1, 1, 0)    \n",
    "left = Action('left', 2, 0, -1)    \n",
    "right = Action('right', 3, 0, 1)    \n",
    "\n",
    "index_to_actions = {}\n",
    "for action in [up, down, left, right]:\n",
    "    index_to_actions[action.index] = action\n",
    "# print(index_to_actions[0].name)\n",
    "str_to_actions = {}\n",
    "for action in [up, down, left, right]:\n",
    "    str_to_actions[action.name] = action\n",
    "#TF End - Adding in actions for action conversion\n",
    "\n",
    "\n",
    "class LightEnvWrapper(gym.Env, LightEnv):\n",
    "    \"\"\"Class that wraps the Lights Environment to make it \n",
    "    compatible with RLLib.\"\"\"\n",
    "\n",
    "    metadata = {\"render.modes\": [\"rgb_array\", \"state_pixels\"]}\n",
    "    \n",
    "    def __init__(self, config: EnvContext):\n",
    "        super().__init__(SCREEN_WIDTH, SCREEN_HEIGHT, SCREEN_TITLE)\n",
    "        self.counting = 0    \n",
    "        self.torch_collected = False\n",
    "        self.torch_collected_count = []\n",
    "        self.mygame = LightEnv\n",
    "        \n",
    "        #The action space is a choice of 4 actions: U/D/L/R.\n",
    "        self.action_space = Discrete(4)\n",
    "        \n",
    "        #The observation space is a fixed image of the current game screen\n",
    "        self.observation_space = Box(low=0, high=255, shape=(84,84, 4), dtype=np.uint8)\n",
    "        \n",
    "        self.counting = 0\n",
    "\n",
    "    def reset(self):\n",
    "        print(\"resetting in wrapper\")\n",
    "        \n",
    "        if self.torch_collected == 1:\n",
    "            print(\"Torch was collected this episode!\")\n",
    "        else:\n",
    "            print(\"Torch was not collected this episode...\")\n",
    "        self.torch_collected_count.append(self.torch_collected)\n",
    "        print(self.torch_collected_count)\n",
    "\n",
    "        self.render(self)\n",
    "        #Resets the state of the environment for a new episode and an initial observation.\n",
    "        obs_mygame = self.mygame.reset(self)\n",
    "        \n",
    "        #Open up the resetted image to verify working correctly.\n",
    "        obs_mygame.show()\n",
    "        \n",
    "        #Convert observation to 84x84 resolution and np array for rllib.\n",
    "        obs = self.convert_observations(obs_mygame)\n",
    "        \n",
    "        return obs\n",
    "\n",
    "    def step(self, action):\n",
    "        self.counting += 1\n",
    "        \n",
    "        #Making sure an action is chosen, either: 0, 1, 2, 3.\n",
    "        assert action in [0, 1, 2, 3] #0-up,1-down,2-left,3-right.\n",
    "        \n",
    "        #Convert the numeric action to a keyword: up, down, left, right.\n",
    "        actions_myenv = index_to_actions[action].name #returns a word, one of: up/down/left/right\n",
    "#         print(f\"action taken: {actions_myenv}\")\n",
    "        \n",
    "        #Update the window with on_update()\n",
    "        self.render(self)\n",
    "        \n",
    "        #Compute observation extracted from the window (800x600), with reward and done flag.\n",
    "        obs, reward, done, torch_collected = self.mygame.step(self,actions_myenv)\n",
    "        if torch_collected == True:\n",
    "            self.torch_collected = 1\n",
    "        else:\n",
    "            self.torch_collected = 0\n",
    "                    \n",
    "#         if self.counting % 33 == 0: #33 steps roughly equates to 1 second in game time\n",
    "#             print(f\"total score is {self.score} at time: {self.mygame.time_taken_reported(self)}\")\n",
    "        \n",
    "        #Convert observation to 84x84 resolution and np array for rllib.\n",
    "        obs_mygame = self.convert_observations(obs)\n",
    "        \n",
    "        #If the reward has been obtained, reset the environment and start again\n",
    "        if done == True:\n",
    "            print(f\"done is {done}, resetting environment in wrapper.\")\n",
    "            self.reset()\n",
    "        \n",
    "        return obs_mygame, reward, done, {}\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        random.seed(seed)\n",
    "\n",
    "    def convert_observations(self, obs_mygame): #resizing and converting to array for rllib processing\n",
    "        # We normalize and concatenate observations\n",
    "        obs = obs_mygame\n",
    "        obs_resized = obs.resize((84,84))\n",
    "        obsarray = np.array(obs_resized)\n",
    "        return obsarray\n",
    "    \n",
    "    def render(self, mode='state_pixels'):\n",
    "        self.mygame.on_update(self, 1/60)\n",
    "        self.mygame.on_draw(self)\n",
    "        test = self.mygame.time_taken_reported(self)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd8f4ad",
   "metadata": {},
   "source": [
    "### Now run the rllib script to train the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a34e7d",
   "metadata": {},
   "source": [
    "Gridsearch attempt below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa7d3fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import gym\n",
    "import ray.rllib.agents.ppo.ppo as ppo\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray import air\n",
    "from ray import tune\n",
    "\n",
    "def evaluation_fn(result):\n",
    "    return result['episode_reward_mean']\n",
    "\n",
    "\n",
    "def objective_fn(config):\n",
    "\n",
    "    \n",
    "    trainer = ppo.PPOTrainer(config=config)\n",
    "\n",
    "    for i in range(100):\n",
    "        # Perform one iteration of training the policy with PPO\n",
    "        result = trainer.train()\n",
    "        intermediate_score = evaluation_fn(result)\n",
    "\n",
    "        # Feed the score back back to Tune.\n",
    "        tune.report(iterations=i, mean_reward=intermediate_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c19dc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "import torch\n",
    "config = PPOConfig().training(gamma=0.9, lr=tune.grid_search([0.001,0.01,0.1]), kl_coeff=0.2, entropy_coeff=1,\n",
    "#                               entropy_coeff_schedule=[[0,1],[1000,0]],\n",
    "                             sgd_minibatch_size=128, num_sgd_iter=60)\\\n",
    "            .resources(num_gpus=0)\\\n",
    "            .rollouts(num_envs_per_worker=1, num_rollout_workers=1, recreate_failed_workers=True)\n",
    "config.normalize_actions=False\n",
    "config.env=LightEnvWrapper\n",
    "config.clip_actions=False\n",
    "config.num_cpus=1\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device='cuda:0'\n",
    "# config.to(device)\n",
    "config = config.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f48cee2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-16 18:11:57,643\tINFO worker.py:1518 -- Started a local Ray instance.\n",
      "2022-09-16 18:12:00,053\tWARNING function_trainable.py:619 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-09-16 18:12:35 (running for 00:00:34.81)<br>Memory usage on this node: 7.4/7.7 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/0.72 GiB heap, 0.0/0.36 GiB objects<br>Result logdir: C:\\Users\\Tim\\ray_results\\objective_fn_2022-09-16_18-12-00<br>Number of trials: 3/3 (3 ERROR)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                              </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>objective_fn_LightEnvWrapper_ad0f9_00000</td><td>ERROR   </td><td>127.0.0.1:12216</td><td style=\"text-align: right;\">0.001</td></tr>\n",
       "<tr><td>objective_fn_LightEnvWrapper_ad0f9_00001</td><td>ERROR   </td><td>               </td><td style=\"text-align: right;\">0.01 </td></tr>\n",
       "<tr><td>objective_fn_LightEnvWrapper_ad0f9_00002</td><td>ERROR   </td><td>               </td><td style=\"text-align: right;\">0.1  </td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 3<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                              </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>objective_fn_LightEnvWrapper_ad0f9_00000</td><td style=\"text-align: right;\">           1</td><td>C:\\Users\\Tim\\ray_results\\objective_fn_2022-09-16_18-12-00\\objective_fn_LightEnvWrapper_ad0f9_00000_0_lr=0.0010_2022-09-16_18-12-00\\error.txt</td></tr>\n",
       "<tr><td>objective_fn_LightEnvWrapper_ad0f9_00001</td><td style=\"text-align: right;\">           1</td><td>C:\\Users\\Tim\\ray_results\\objective_fn_2022-09-16_18-12-00\\objective_fn_LightEnvWrapper_ad0f9_00001_1_lr=0.0100_2022-09-16_18-12-11\\error.txt</td></tr>\n",
       "<tr><td>objective_fn_LightEnvWrapper_ad0f9_00002</td><td style=\"text-align: right;\">           1</td><td>C:\\Users\\Tim\\ray_results\\objective_fn_2022-09-16_18-12-00\\objective_fn_LightEnvWrapper_ad0f9_00002_2_lr=0.1000_2022-09-16_18-12-22\\error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\util\\placement_group.py:78: DeprecationWarning: placement_group parameter is deprecated. Use scheduling_strategy=PlacementGroupSchedulingStrategy(...) instead, see the usage at https://docs.ray.io/en/releases-2.0.0/ray-core/package-ref.html#ray-remote.\n",
      "  return bundle_reservation_check.options(\n",
      "C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\_private\\ray_option_utils.py:266: DeprecationWarning: Setting 'object_store_memory' for actors is deprecated since it doesn't actually reserve the required object store memory. Use object spilling that's enabled by default (https://docs.ray.io/en/releases-2.0.0/ray-core/objects/object-spilling.html) instead to bypass the object store memory size limitation.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\actor.py:637: DeprecationWarning: placement_group parameter is deprecated. Use scheduling_strategy=PlacementGroupSchedulingStrategy(...) instead, see the usage at https://docs.ray.io/en/releases-2.0.0/ray-core/package-ref.html#ray-remote.\n",
      "  return actor_cls._remote(args=args, kwargs=kwargs, **updated_options)\n",
      "C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\actor.py:637: DeprecationWarning: placement_group_bundle_index parameter is deprecated. Use scheduling_strategy=PlacementGroupSchedulingStrategy(...) instead, see the usage at https://docs.ray.io/en/releases-2.0.0/ray-core/package-ref.html#ray-remote.\n",
      "  return actor_cls._remote(args=args, kwargs=kwargs, **updated_options)\n",
      "C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\actor.py:637: DeprecationWarning: placement_group_capture_child_tasks parameter is deprecated. Use scheduling_strategy=PlacementGroupSchedulingStrategy(...) instead, see the usage at https://docs.ray.io/en/releases-2.0.0/ray-core/package-ref.html#ray-remote.\n",
      "  return actor_cls._remote(args=args, kwargs=kwargs, **updated_options)\n",
      "\u001b[2m\u001b[36m(pid=12216)\u001b[0m Windows fatal exception: code 0xc0000139\n",
      "\u001b[2m\u001b[36m(pid=12216)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=12216)\u001b[0m C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\tensorflow_probability\\python\\__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=12216)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=12216)\u001b[0m 2022-09-16 18:12:11,542\tWARNING util.py:65 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(objective_fn pid=12216)\u001b[0m 2022-09-16 18:12:11,607\tERROR function_trainable.py:298 -- Runner Thread raised error.\n",
      "\u001b[2m\u001b[36m(objective_fn pid=12216)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(objective_fn pid=12216)\u001b[0m   File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 289, in run\n",
      "\u001b[2m\u001b[36m(objective_fn pid=12216)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(objective_fn pid=12216)\u001b[0m   File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 362, in entrypoint\n",
      "\u001b[2m\u001b[36m(objective_fn pid=12216)\u001b[0m     return self._trainable_func(\n",
      "\u001b[2m\u001b[36m(objective_fn pid=12216)\u001b[0m   File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "\u001b[2m\u001b[36m(objective_fn pid=12216)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(objective_fn pid=12216)\u001b[0m   File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 684, in _trainable_func\n",
      "\u001b[2m\u001b[36m(objective_fn pid=12216)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(objective_fn pid=12216)\u001b[0m   File \"C:\\Users\\Tim\\AppData\\Local\\Temp\\ipykernel_26000\\3219069064.py\", line 15, in objective_fn\n",
      "\u001b[2m\u001b[36m(objective_fn pid=12216)\u001b[0m   File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py\", line 308, in __init__\n",
      "\u001b[2m\u001b[36m(objective_fn pid=12216)\u001b[0m     super().__init__(config=config, logger_creator=logger_creator, **kwargs)\n",
      "\u001b[2m\u001b[36m(objective_fn pid=12216)\u001b[0m   File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\tune\\trainable\\trainable.py\", line 157, in __init__\n",
      "\u001b[2m\u001b[36m(objective_fn pid=12216)\u001b[0m     self.setup(copy.deepcopy(self.config))\n",
      "\u001b[2m\u001b[36m(objective_fn pid=12216)\u001b[0m   File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py\", line 333, in setup\n",
      "\u001b[2m\u001b[36m(objective_fn pid=12216)\u001b[0m     self.config = self.merge_trainer_configs(\n",
      "\u001b[2m\u001b[36m(objective_fn pid=12216)\u001b[0m   File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py\", line 1796, in merge_trainer_configs\n",
      "\u001b[2m\u001b[36m(objective_fn pid=12216)\u001b[0m     return deep_update(\n",
      "\u001b[2m\u001b[36m(objective_fn pid=12216)\u001b[0m   File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\_private\\dict.py\", line 60, in deep_update\n",
      "\u001b[2m\u001b[36m(objective_fn pid=12216)\u001b[0m     raise Exception(\"Unknown config parameter `{}` \".format(k))\n",
      "\u001b[2m\u001b[36m(objective_fn pid=12216)\u001b[0m Exception: Unknown config parameter `num_cpus` \n",
      "\u001b[2m\u001b[36m(pid=10128)\u001b[0m Windows fatal exception: code 0xc0000139\n",
      "\u001b[2m\u001b[36m(pid=10128)\u001b[0m \n",
      "2022-09-16 18:12:17,162\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=12216, ip=127.0.0.1, repr=objective_fn)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 662, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 666, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 613, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 674, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\tune\\trainable\\trainable.py\", line 347, in train\n",
      "    result = self.step()\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 417, in step\n",
      "    self._report_thread_runner_error(block=True)\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 589, in _report_thread_runner_error\n",
      "    raise e\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 289, in run\n",
      "    self._entrypoint()\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 362, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 684, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"C:\\Users\\Tim\\AppData\\Local\\Temp\\ipykernel_26000\\3219069064.py\", line 15, in objective_fn\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py\", line 308, in __init__\n",
      "    super().__init__(config=config, logger_creator=logger_creator, **kwargs)\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\tune\\trainable\\trainable.py\", line 157, in __init__\n",
      "    self.setup(copy.deepcopy(self.config))\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py\", line 333, in setup\n",
      "    self.config = self.merge_trainer_configs(\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py\", line 1796, in merge_trainer_configs\n",
      "    return deep_update(\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\_private\\dict.py\", line 60, in deep_update\n",
      "    raise Exception(\"Unknown config parameter `{}` \".format(k))\n",
      "Exception: Unknown config parameter `num_cpus`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=10128)\u001b[0m C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\tensorflow_probability\\python\\__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=10128)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=10128)\u001b[0m 2022-09-16 18:12:22,464\tERROR worker.py:756 -- Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::ImplicitFunc.__init__()\u001b[39m (pid=10128, ip=127.0.0.1, repr=objective_fn)\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=10128)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 620, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=10128)\u001b[0m   File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\_private\\memory_monitor.py\", line 162, in raise_if_low_memory\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=10128)\u001b[0m     raise RayOutOfMemoryError(\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=10128)\u001b[0m ray._private.memory_monitor.RayOutOfMemoryError: More than 95% of the memory on node DESKTOP-BKAPO4O is used (7.38 / 7.73 GB). The top 10 memory consumers are:\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=10128)\u001b[0m \n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=10128)\u001b[0m PID\tMEM\tCOMMAND\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=10128)\u001b[0m 12216\t0.53GiB\tC:\\Users\\Tim\\Anaconda3\\envs\\rllib\\python.exe C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=10128)\u001b[0m 10128\t0.44GiB\tC:\\Users\\Tim\\Anaconda3\\envs\\rllib\\python.exe C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=10128)\u001b[0m 26000\t0.39GiB\tC:\\Users\\Tim\\Anaconda3\\envs\\rllib\\python.exe -m ipykernel_launcher -f C:\\Users\\Tim\\AppData\\Roaming\\j\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=10128)\u001b[0m 4720\t0.36GiB\tC:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe --type=renderer --display-capture-permi\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=10128)\u001b[0m 12836\t0.33GiB\tC:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe --type=renderer --display-capture-permi\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=10128)\u001b[0m 22116\t0.28GiB\tC:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe --type=gpu-process --gpu-preferences=UA\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=10128)\u001b[0m 21804\t0.13GiB\tC:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe --type=renderer --display-capture-permi\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=10128)\u001b[0m 3384\t0.11GiB\tC:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe --no-startup-window --win-session-start\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=10128)\u001b[0m 27332\t0.1GiB\tC:\\WINDOWS\\Explorer.EXE\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=10128)\u001b[0m 26228\t0.1GiB\tC:\\Program Files (x86)\\Overwolf\\0.204.0.1\\OverwolfBrowser.exe --type=renderer --no-sandbox --autopla\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=10128)\u001b[0m \n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=10128)\u001b[0m In addition, up to 0.0 GiB of shared memory is currently being used by the Ray object store.\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=10128)\u001b[0m ---\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=10128)\u001b[0m --- Tip: Use the `ray memory` command to list active objects in the cluster.\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=10128)\u001b[0m --- To disable OOM exceptions, set RAY_DISABLE_MEMORY_MONITOR=1.\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=10128)\u001b[0m ---\n",
      "\u001b[2m\u001b[36m(pid=32644)\u001b[0m Windows fatal exception: code 0xc0000139\n",
      "\u001b[2m\u001b[36m(pid=32644)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=32644)\u001b[0m C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\tensorflow_probability\\python\\__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=32644)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "2022-09-16 18:12:34,943\tERROR trial_runner.py:980 -- Trial objective_fn_LightEnvWrapper_ad0f9_00000: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\tune\\execution\\ray_trial_executor.py\", line 989, in get_next_executor_event\n",
      "    future_result = ray.get(ready_future)\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\_private\\worker.py\", line 2275, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=12216, ip=127.0.0.1, repr=objective_fn)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 662, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 666, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 613, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 674, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\tune\\trainable\\trainable.py\", line 347, in train\n",
      "    result = self.step()\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 417, in step\n",
      "    self._report_thread_runner_error(block=True)\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 589, in _report_thread_runner_error\n",
      "    raise e\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 289, in run\n",
      "    self._entrypoint()\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 362, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 684, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"C:\\Users\\Tim\\AppData\\Local\\Temp\\ipykernel_26000\\3219069064.py\", line 15, in objective_fn\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py\", line 308, in __init__\n",
      "    super().__init__(config=config, logger_creator=logger_creator, **kwargs)\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\tune\\trainable\\trainable.py\", line 157, in __init__\n",
      "    self.setup(copy.deepcopy(self.config))\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py\", line 333, in setup\n",
      "    self.config = self.merge_trainer_configs(\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py\", line 1796, in merge_trainer_configs\n",
      "    return deep_update(\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\_private\\dict.py\", line 60, in deep_update\n",
      "    raise Exception(\"Unknown config parameter `{}` \".format(k))\n",
      "Exception: Unknown config parameter `num_cpus`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for objective_fn_LightEnvWrapper_ad0f9_00000:\n",
      "  date: 2022-09-16_18-12-11\n",
      "  experiment_id: bb4aad0d16744006b1176d86dcf5ec98\n",
      "  hostname: DESKTOP-BKAPO4O\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 12216\n",
      "  timestamp: 1663348331\n",
      "  trial_id: ad0f9_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-16 18:12:34,979\tERROR trial_runner.py:980 -- Trial objective_fn_LightEnvWrapper_ad0f9_00002: Error processing event.\n",
      "ray.tune.error._TuneNoNextExecutorEventError: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\tune\\execution\\ray_trial_executor.py\", line 989, in get_next_executor_event\n",
      "    future_result = ray.get(ready_future)\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\_private\\worker.py\", line 2277, in get\n",
      "    raise value\n",
      "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, \u001b[36mray::ImplicitFunc.__init__()\u001b[39m (pid=32644, ip=127.0.0.1, repr=objective_fn)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 620, in ray._raylet.execute_task\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\_private\\memory_monitor.py\", line 162, in raise_if_low_memory\n",
      "    raise RayOutOfMemoryError(\n",
      "ray._private.memory_monitor.RayOutOfMemoryError: More than 95% of the memory on node DESKTOP-BKAPO4O is used (7.5 / 7.73 GB). The top 10 memory consumers are:\n",
      "\n",
      "PID\tMEM\tCOMMAND\n",
      "12216\t0.53GiB\tC:\\Users\\Tim\\Anaconda3\\envs\\rllib\\python.exe C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\n",
      "32644\t0.4GiB\tC:\\Users\\Tim\\Anaconda3\\envs\\rllib\\python.exe C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\n",
      "12836\t0.4GiB\tC:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe --type=renderer --display-capture-permi\n",
      "4720\t0.24GiB\tC:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe --type=renderer --display-capture-permi\n",
      "26000\t0.23GiB\tC:\\Users\\Tim\\Anaconda3\\envs\\rllib\\python.exe -m ipykernel_launcher -f C:\\Users\\Tim\\AppData\\Roaming\\j\n",
      "22116\t0.22GiB\tC:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe --type=gpu-process --gpu-preferences=UA\n",
      "3384\t0.15GiB\tC:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe --no-startup-window --win-session-start\n",
      "22164\t0.14GiB\tC:\\Users\\Tim\\AppData\\Local\\Microsoft\\OneDrive\\OneDrive.exe /background\n",
      "7788\t0.13GiB\tC:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe --type=renderer --instant-process --dis\n",
      "27332\t0.1GiB\tC:\\WINDOWS\\Explorer.EXE\n",
      "\n",
      "In addition, up to 0.0 GiB of shared memory is currently being used by the Ray object store.\n",
      "---\n",
      "--- Tip: Use the `ray memory` command to list active objects in the cluster.\n",
      "--- To disable OOM exceptions, set RAY_DISABLE_MEMORY_MONITOR=1.\n",
      "---\n",
      "\n",
      "2022-09-16 18:12:34,984\tERROR trial_runner.py:980 -- Trial objective_fn_LightEnvWrapper_ad0f9_00001: Error processing event.\n",
      "ray.tune.error._TuneNoNextExecutorEventError: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\tune\\execution\\ray_trial_executor.py\", line 989, in get_next_executor_event\n",
      "    future_result = ray.get(ready_future)\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\_private\\worker.py\", line 2277, in get\n",
      "    raise value\n",
      "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, \u001b[36mray::ImplicitFunc.__init__()\u001b[39m (pid=10128, ip=127.0.0.1, repr=objective_fn)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 620, in ray._raylet.execute_task\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\_private\\memory_monitor.py\", line 162, in raise_if_low_memory\n",
      "    raise RayOutOfMemoryError(\n",
      "ray._private.memory_monitor.RayOutOfMemoryError: More than 95% of the memory on node DESKTOP-BKAPO4O is used (7.38 / 7.73 GB). The top 10 memory consumers are:\n",
      "\n",
      "PID\tMEM\tCOMMAND\n",
      "12216\t0.53GiB\tC:\\Users\\Tim\\Anaconda3\\envs\\rllib\\python.exe C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\n",
      "10128\t0.44GiB\tC:\\Users\\Tim\\Anaconda3\\envs\\rllib\\python.exe C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\n",
      "26000\t0.39GiB\tC:\\Users\\Tim\\Anaconda3\\envs\\rllib\\python.exe -m ipykernel_launcher -f C:\\Users\\Tim\\AppData\\Roaming\\j\n",
      "4720\t0.36GiB\tC:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe --type=renderer --display-capture-permi\n",
      "12836\t0.33GiB\tC:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe --type=renderer --display-capture-permi\n",
      "22116\t0.28GiB\tC:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe --type=gpu-process --gpu-preferences=UA\n",
      "21804\t0.13GiB\tC:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe --type=renderer --display-capture-permi\n",
      "3384\t0.11GiB\tC:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe --no-startup-window --win-session-start\n",
      "27332\t0.1GiB\tC:\\WINDOWS\\Explorer.EXE\n",
      "26228\t0.1GiB\tC:\\Program Files (x86)\\Overwolf\\0.204.0.1\\OverwolfBrowser.exe --type=renderer --no-sandbox --autopla\n",
      "\n",
      "In addition, up to 0.0 GiB of shared memory is currently being used by the Ray object store.\n",
      "---\n",
      "--- Tip: Use the `ray memory` command to list active objects in the cluster.\n",
      "--- To disable OOM exceptions, set RAY_DISABLE_MEMORY_MONITOR=1.\n",
      "---\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for objective_fn_LightEnvWrapper_ad0f9_00002:\n",
      "  trial_id: ad0f9_00002\n",
      "  \n",
      "Result for objective_fn_LightEnvWrapper_ad0f9_00001:\n",
      "  trial_id: ad0f9_00001\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ImplicitFunc pid=32644)\u001b[0m 2022-09-16 18:12:34,935\tERROR worker.py:756 -- Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::ImplicitFunc.__init__()\u001b[39m (pid=32644, ip=127.0.0.1, repr=objective_fn)\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=32644)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 620, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=32644)\u001b[0m   File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\_private\\memory_monitor.py\", line 162, in raise_if_low_memory\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=32644)\u001b[0m     raise RayOutOfMemoryError(\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=32644)\u001b[0m ray._private.memory_monitor.RayOutOfMemoryError: More than 95% of the memory on node DESKTOP-BKAPO4O is used (7.5 / 7.73 GB). The top 10 memory consumers are:\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=32644)\u001b[0m \n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=32644)\u001b[0m PID\tMEM\tCOMMAND\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=32644)\u001b[0m 12216\t0.53GiB\tC:\\Users\\Tim\\Anaconda3\\envs\\rllib\\python.exe C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=32644)\u001b[0m 32644\t0.4GiB\tC:\\Users\\Tim\\Anaconda3\\envs\\rllib\\python.exe C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=32644)\u001b[0m 12836\t0.4GiB\tC:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe --type=renderer --display-capture-permi\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=32644)\u001b[0m 4720\t0.24GiB\tC:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe --type=renderer --display-capture-permi\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=32644)\u001b[0m 26000\t0.23GiB\tC:\\Users\\Tim\\Anaconda3\\envs\\rllib\\python.exe -m ipykernel_launcher -f C:\\Users\\Tim\\AppData\\Roaming\\j\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=32644)\u001b[0m 22116\t0.22GiB\tC:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe --type=gpu-process --gpu-preferences=UA\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=32644)\u001b[0m 3384\t0.15GiB\tC:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe --no-startup-window --win-session-start\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=32644)\u001b[0m 22164\t0.14GiB\tC:\\Users\\Tim\\AppData\\Local\\Microsoft\\OneDrive\\OneDrive.exe /background\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=32644)\u001b[0m 7788\t0.13GiB\tC:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe --type=renderer --instant-process --dis\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=32644)\u001b[0m 27332\t0.1GiB\tC:\\WINDOWS\\Explorer.EXE\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=32644)\u001b[0m \n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=32644)\u001b[0m In addition, up to 0.0 GiB of shared memory is currently being used by the Ray object store.\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=32644)\u001b[0m ---\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=32644)\u001b[0m --- Tip: Use the `ray memory` command to list active objects in the cluster.\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=32644)\u001b[0m --- To disable OOM exceptions, set RAY_DISABLE_MEMORY_MONITOR=1.\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=32644)\u001b[0m ---\n",
      "2022-09-16 18:12:35,016\tERROR ray_trial_executor.py:103 -- An exception occurred when trying to stop the Ray actor:Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\tune\\execution\\ray_trial_executor.py\", line 94, in _post_stop_cleanup\n",
      "    ray.get(future, timeout=0)\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\_private\\worker.py\", line 2277, in get\n",
      "    raise value\n",
      "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, \u001b[36mray::ImplicitFunc.__init__()\u001b[39m (pid=10128, ip=127.0.0.1, repr=objective_fn)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 620, in ray._raylet.execute_task\n",
      "  File \"C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\_private\\memory_monitor.py\", line 162, in raise_if_low_memory\n",
      "    raise RayOutOfMemoryError(\n",
      "ray._private.memory_monitor.RayOutOfMemoryError: More than 95% of the memory on node DESKTOP-BKAPO4O is used (7.38 / 7.73 GB). The top 10 memory consumers are:\n",
      "\n",
      "PID\tMEM\tCOMMAND\n",
      "12216\t0.53GiB\tC:\\Users\\Tim\\Anaconda3\\envs\\rllib\\python.exe C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\n",
      "10128\t0.44GiB\tC:\\Users\\Tim\\Anaconda3\\envs\\rllib\\python.exe C:\\Users\\Tim\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\n",
      "26000\t0.39GiB\tC:\\Users\\Tim\\Anaconda3\\envs\\rllib\\python.exe -m ipykernel_launcher -f C:\\Users\\Tim\\AppData\\Roaming\\j\n",
      "4720\t0.36GiB\tC:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe --type=renderer --display-capture-permi\n",
      "12836\t0.33GiB\tC:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe --type=renderer --display-capture-permi\n",
      "22116\t0.28GiB\tC:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe --type=gpu-process --gpu-preferences=UA\n",
      "21804\t0.13GiB\tC:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe --type=renderer --display-capture-permi\n",
      "3384\t0.11GiB\tC:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe --no-startup-window --win-session-start\n",
      "27332\t0.1GiB\tC:\\WINDOWS\\Explorer.EXE\n",
      "26228\t0.1GiB\tC:\\Program Files (x86)\\Overwolf\\0.204.0.1\\OverwolfBrowser.exe --type=renderer --no-sandbox --autopla\n",
      "\n",
      "In addition, up to 0.0 GiB of shared memory is currently being used by the Ray object store.\n",
      "---\n",
      "--- Tip: Use the `ray memory` command to list active objects in the cluster.\n",
      "--- To disable OOM exceptions, set RAY_DISABLE_MEMORY_MONITOR=1.\n",
      "---\n",
      "\n"
     ]
    },
    {
     "ename": "TuneError",
     "evalue": "('Trials did not complete', [objective_fn_LightEnvWrapper_ad0f9_00000, objective_fn_LightEnvWrapper_ad0f9_00001, objective_fn_LightEnvWrapper_ad0f9_00002])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m analysis \u001b[38;5;241m=\u001b[39m \u001b[43mtune\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobjective_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean_reward\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rllib\\lib\\site-packages\\ray\\tune\\tune.py:752\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, max_concurrent_trials, _experiment_checkpoint_dir, _remote)\u001b[0m\n\u001b[0;32m    750\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m incomplete_trials:\n\u001b[0;32m    751\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m raise_on_failed_trial \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msignal\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 752\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TuneError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrials did not complete\u001b[39m\u001b[38;5;124m\"\u001b[39m, incomplete_trials)\n\u001b[0;32m    753\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    754\u001b[0m         logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrials did not complete: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, incomplete_trials)\n",
      "\u001b[1;31mTuneError\u001b[0m: ('Trials did not complete', [objective_fn_LightEnvWrapper_ad0f9_00000, objective_fn_LightEnvWrapper_ad0f9_00001, objective_fn_LightEnvWrapper_ad0f9_00002])"
     ]
    }
   ],
   "source": [
    "analysis = tune.run(\n",
    "        objective_fn,\n",
    "        metric=\"mean_reward\",\n",
    "        mode=\"max\",\n",
    "        num_samples=1,\n",
    "        config=config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rllib",
   "language": "python",
   "name": "rllib"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
