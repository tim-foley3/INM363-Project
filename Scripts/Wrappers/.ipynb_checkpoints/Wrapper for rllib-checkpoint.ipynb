{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c04aa84b",
   "metadata": {},
   "source": [
    "### My wrapper for Light Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df76024a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in c:\\users\\tim\\anaconda3\\lib\\site-packages (0.25.1)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\tim\\anaconda3\\lib\\site-packages (from gym) (1.20.1)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in c:\\users\\tim\\anaconda3\\lib\\site-packages (from gym) (0.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\tim\\anaconda3\\lib\\site-packages (from gym) (4.11.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\tim\\anaconda3\\lib\\site-packages (from gym) (1.2.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\tim\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.8.0->gym) (3.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84136113",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tim\\Anaconda3\\envs\\gpu2\\lib\\site-packages\\gym\\core.py:26: UserWarning: \u001b[33mWARN: Gym minimally supports python 3.6 as the python foundation not longer supports the version, please update your version to 3.7+\u001b[0m\n",
      "  \"Gym minimally supports python 3.6 as the python foundation not longer supports the version, please update your version to 3.7+\"\n"
     ]
    }
   ],
   "source": [
    "import gym.spaces\n",
    "from gym.spaces import Discrete, Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5f710c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random, math\n",
    "import numpy as np\n",
    "from MyGameExplodingBombsCopy import MyGameExplodingBombs\n",
    "import gym.spaces\n",
    "from gym.spaces import Discrete, Box\n",
    "\n",
    "from ray.rllib.env.env_context import EnvContext\n",
    "from ray.rllib.models import ModelCatalog\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "\n",
    "\n",
    "#TF Start - Adding in actions for action conversion\n",
    "\n",
    "# COnvenient data structure to hold information about actions\n",
    "Action = namedtuple('Action', 'name index delta_i delta_j')\n",
    "\n",
    "up = Action('up', 0, -1, 0)    \n",
    "down = Action('down', 1, 1, 0)    \n",
    "left = Action('left', 2, 0, -1)    \n",
    "right = Action('right', 3, 0, 1)    \n",
    "\n",
    "index_to_actions = {}\n",
    "for action in [up, down, left, right]:\n",
    "    index_to_actions[action.index] = action\n",
    "\n",
    "str_to_actions = {}\n",
    "for action in [up, down, left, right]:\n",
    "    str_to_actions[action.name] = action\n",
    "#TF End - Adding in actions for action conversion\n",
    "\n",
    "    \n",
    "\n",
    "class LightEnv(gym.Env):\n",
    "    \"\"\"Class that wraps the Lights Environment to make it \n",
    "    compatible with RLLib.\"\"\"\n",
    "\n",
    "    metadata = {\"render.modes\": [\"rgb_array\"]}\n",
    "    \n",
    "    def __init__(self, config: EnvContext):\n",
    "\n",
    "        game_size = config.get(\"size_env\")\n",
    "\n",
    "        self.mygame = MyGameExplodingBombs\n",
    "        #The action space is a choice of 9 actions: U/D/L/R/UR/DR/DL/UL/DO NOTHING. Not continuous\n",
    "        #because speed of agent is fixed. Or potentially just 4: U/D/L/R.\n",
    "        self.action_space = Discrete(4)\n",
    "        #The observation space is continuous, as there is a varying amount to be seen based on the\n",
    "        #proximity to the light source, depth of shadow etc. Not sure what to say though.. <<HELP>>.\n",
    "        #I guess consequences of actions is either just 0, -1 or +100?\n",
    "        self.observation_space = Box(-1.0, 1.0, shape=(27,), dtype=np.float32)\n",
    "        \n",
    "\n",
    "    def reset(self):\n",
    "        #This method resets the state of the environment for a new episode and also returns an \n",
    "        #initial observation.\n",
    "        obs_mygame = self.MyGameExplodingBombs.reset()\n",
    "        print(\"obs_mygame: \", obs_mygame)\n",
    "        obs = self.convert_observations(obs_dungeon)\n",
    "        return obs\n",
    "\n",
    "    def step(self, action):\n",
    "        \n",
    "        assert action in [0, 1, 2, 3]\n",
    "        #actions for my env = self.convert(actions from rllib)\n",
    "        actions_myenv = index_to_actions[action].name\n",
    "        \n",
    "#         action_str = index_to_actions[action].name\n",
    "\n",
    "        # Run the game with actions passed. So somehting like \n",
    "        # window = MyGameExplodingBombs(SCREEN_WIDTH, SCREEN_HEIGHT, SCREEN_TITLE)\n",
    "        # arcade.run()\n",
    "    \n",
    "        obs_dungeon, reward, done = self.dungeon.step(action_str)\n",
    "        obs = self.convert_observations(obs_dungeon)\n",
    "\n",
    "        return obs, reward, done, {}\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        random.seed(seed)\n",
    "\n",
    "    def convert_observations(self, dungeon_obs):\n",
    "        # We normalize and concatenate observations\n",
    "\n",
    "        relative_coord = dungeon_obs['relative_coordinates']/self.dungeon.size\n",
    "        surroundings = dungeon_obs['surroundings'] / 4\n",
    "        \n",
    "        obs = np.concatenate([relative_coord, surroundings.flatten()])\n",
    "\n",
    "        return obs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154db1c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58e1a438",
   "metadata": {},
   "source": [
    "### Example custom wrapper from ray documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f27a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCorridor(gym.Env):\n",
    "    \"\"\"Example of a custom env in which you have to walk down a corridor.\n",
    "    You can configure the length of the corridor via the env config.\"\"\"\n",
    "\n",
    "    def __init__(self, config: EnvContext):\n",
    "        self.end_pos = config[\"corridor_length\"]\n",
    "        self.cur_pos = 0\n",
    "        self.action_space = Discrete(2)\n",
    "        self.observation_space = Box(0.0, self.end_pos, shape=(1,), dtype=np.float32)\n",
    "        # Set the seed. This is only used for the final (reach goal) reward.\n",
    "        self.seed(config.worker_index * config.num_workers)\n",
    "\n",
    "    def reset(self):\n",
    "        self.cur_pos = 0\n",
    "        return [self.cur_pos]\n",
    "\n",
    "    def step(self, action):\n",
    "        assert action in [0, 1], action\n",
    "        if action == 0 and self.cur_pos > 0:\n",
    "            self.cur_pos -= 1\n",
    "        elif action == 1:\n",
    "            self.cur_pos += 1\n",
    "        done = self.cur_pos >= self.end_pos\n",
    "        # Produce a random reward when we reach the goal.\n",
    "        return [self.cur_pos], random.random() * 2 if done else -0.1, done, {}\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa8c26b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu2",
   "language": "python",
   "name": "gpu2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
